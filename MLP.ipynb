{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T18:21:10.171267Z",
     "start_time": "2024-11-07T18:20:58.807685Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\"/home/kongge/projects/Phd/data/all_labels.csv\")\n",
    "prs_df = pd.read_csv('/home/kongge/projects/Phd/data/Only_PGS.csv')\n",
    "data = pd.merge(prs_df, label_df, left_on='FID', right_on='eid')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:35:10.219013Z",
     "start_time": "2024-11-07T12:34:59.518553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(336979, 187)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:35:29.086006Z",
     "start_time": "2024-11-07T12:35:29.045385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "feature_columns = prs_df.columns.drop('FID')\n",
    "label_columns = label_df.columns.drop('eid')\n",
    "X = data[feature_columns].values\n",
    "y = data[label_columns].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:39:08.193586Z",
     "start_time": "2024-11-07T12:39:05.941609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:39:22.020409Z",
     "start_time": "2024-11-07T12:39:18.454024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:39:52.541802Z",
     "start_time": "2024-11-07T12:39:51.541037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:40:17.331439Z",
     "start_time": "2024-11-07T12:40:17.316313Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MLP(input_size, output_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:43:00.732065Z",
     "start_time": "2024-11-07T12:43:00.689994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:52:59.994911Z",
     "start_time": "2024-11-07T12:52:59.985478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.0568\n",
      "Epoch [2/200], Loss: 0.0568\n",
      "Epoch [3/200], Loss: 0.0568\n",
      "Epoch [4/200], Loss: 0.0568\n",
      "Epoch [5/200], Loss: 0.0568\n",
      "Epoch [6/200], Loss: 0.0568\n",
      "Epoch [7/200], Loss: 0.0568\n",
      "Epoch [8/200], Loss: 0.0567\n",
      "Epoch [9/200], Loss: 0.0567\n",
      "Epoch [10/200], Loss: 0.0568\n",
      "Epoch [11/200], Loss: 0.0567\n",
      "Epoch [12/200], Loss: 0.0567\n",
      "Epoch [13/200], Loss: 0.0567\n",
      "Epoch [14/200], Loss: 0.0567\n",
      "Epoch [15/200], Loss: 0.0568\n",
      "Epoch [16/200], Loss: 0.0567\n",
      "Epoch [17/200], Loss: 0.0567\n",
      "Epoch [18/200], Loss: 0.0567\n",
      "Epoch [19/200], Loss: 0.0567\n",
      "Epoch [20/200], Loss: 0.0567\n",
      "Epoch [21/200], Loss: 0.0567\n",
      "Epoch [22/200], Loss: 0.0567\n",
      "Epoch [23/200], Loss: 0.0567\n",
      "Epoch [24/200], Loss: 0.0567\n",
      "Epoch [25/200], Loss: 0.0567\n",
      "Epoch [26/200], Loss: 0.0567\n",
      "Epoch [27/200], Loss: 0.0567\n",
      "Epoch [28/200], Loss: 0.0567\n",
      "Epoch [29/200], Loss: 0.0567\n",
      "Epoch [30/200], Loss: 0.0567\n",
      "Epoch [31/200], Loss: 0.0567\n",
      "Epoch [32/200], Loss: 0.0567\n",
      "Epoch [33/200], Loss: 0.0567\n",
      "Epoch [34/200], Loss: 0.0567\n",
      "Epoch [35/200], Loss: 0.0567\n",
      "Epoch [36/200], Loss: 0.0567\n",
      "Epoch [37/200], Loss: 0.0567\n",
      "Epoch [38/200], Loss: 0.0567\n",
      "Epoch [39/200], Loss: 0.0567\n",
      "Epoch [40/200], Loss: 0.0567\n",
      "Epoch [41/200], Loss: 0.0567\n",
      "Epoch [42/200], Loss: 0.0567\n",
      "Epoch [43/200], Loss: 0.0567\n",
      "Epoch [44/200], Loss: 0.0567\n",
      "Epoch [45/200], Loss: 0.0567\n",
      "Epoch [46/200], Loss: 0.0567\n",
      "Epoch [47/200], Loss: 0.0567\n",
      "Epoch [48/200], Loss: 0.0567\n",
      "Epoch [49/200], Loss: 0.0567\n",
      "Epoch [50/200], Loss: 0.0567\n",
      "Epoch [51/200], Loss: 0.0567\n",
      "Epoch [52/200], Loss: 0.0567\n",
      "Epoch [53/200], Loss: 0.0567\n",
      "Epoch [54/200], Loss: 0.0567\n",
      "Epoch [55/200], Loss: 0.0567\n",
      "Epoch [56/200], Loss: 0.0567\n",
      "Epoch [57/200], Loss: 0.0567\n",
      "Epoch [58/200], Loss: 0.0567\n",
      "Epoch [59/200], Loss: 0.0567\n",
      "Epoch [60/200], Loss: 0.0567\n",
      "Epoch [61/200], Loss: 0.0567\n",
      "Epoch [62/200], Loss: 0.0567\n",
      "Epoch [63/200], Loss: 0.0567\n",
      "Epoch [64/200], Loss: 0.0567\n",
      "Epoch [65/200], Loss: 0.0567\n",
      "Epoch [66/200], Loss: 0.0567\n",
      "Epoch [67/200], Loss: 0.0567\n",
      "Epoch [68/200], Loss: 0.0567\n",
      "Epoch [69/200], Loss: 0.0567\n",
      "Epoch [70/200], Loss: 0.0567\n",
      "Epoch [71/200], Loss: 0.0567\n",
      "Epoch [72/200], Loss: 0.0567\n",
      "Epoch [73/200], Loss: 0.0567\n",
      "Epoch [74/200], Loss: 0.0567\n",
      "Epoch [75/200], Loss: 0.0567\n",
      "Epoch [76/200], Loss: 0.0567\n",
      "Epoch [77/200], Loss: 0.0567\n",
      "Epoch [78/200], Loss: 0.0567\n",
      "Epoch [79/200], Loss: 0.0567\n",
      "Epoch [80/200], Loss: 0.0567\n",
      "Epoch [81/200], Loss: 0.0567\n",
      "Epoch [82/200], Loss: 0.0567\n",
      "Epoch [83/200], Loss: 0.0567\n",
      "Epoch [84/200], Loss: 0.0567\n",
      "Epoch [85/200], Loss: 0.0567\n",
      "Epoch [86/200], Loss: 0.0567\n",
      "Epoch [87/200], Loss: 0.0567\n",
      "Epoch [88/200], Loss: 0.0567\n",
      "Epoch [89/200], Loss: 0.0567\n",
      "Epoch [90/200], Loss: 0.0567\n",
      "Epoch [91/200], Loss: 0.0567\n",
      "Epoch [92/200], Loss: 0.0567\n",
      "Epoch [93/200], Loss: 0.0567\n",
      "Epoch [94/200], Loss: 0.0567\n",
      "Epoch [95/200], Loss: 0.0567\n",
      "Epoch [96/200], Loss: 0.0567\n",
      "Epoch [97/200], Loss: 0.0566\n",
      "Epoch [98/200], Loss: 0.0567\n",
      "Epoch [99/200], Loss: 0.0567\n",
      "Epoch [100/200], Loss: 0.0567\n",
      "Epoch [101/200], Loss: 0.0567\n",
      "Epoch [102/200], Loss: 0.0567\n",
      "Epoch [103/200], Loss: 0.0567\n",
      "Epoch [104/200], Loss: 0.0567\n",
      "Epoch [105/200], Loss: 0.0567\n",
      "Epoch [106/200], Loss: 0.0567\n",
      "Epoch [107/200], Loss: 0.0567\n",
      "Epoch [108/200], Loss: 0.0567\n",
      "Epoch [109/200], Loss: 0.0567\n",
      "Epoch [110/200], Loss: 0.0567\n",
      "Epoch [111/200], Loss: 0.0567\n",
      "Epoch [112/200], Loss: 0.0567\n",
      "Epoch [113/200], Loss: 0.0567\n",
      "Epoch [114/200], Loss: 0.0566\n",
      "Epoch [115/200], Loss: 0.0566\n",
      "Epoch [116/200], Loss: 0.0567\n",
      "Epoch [117/200], Loss: 0.0567\n",
      "Epoch [118/200], Loss: 0.0566\n",
      "Epoch [119/200], Loss: 0.0567\n",
      "Epoch [120/200], Loss: 0.0566\n",
      "Epoch [121/200], Loss: 0.0567\n",
      "Epoch [122/200], Loss: 0.0566\n",
      "Epoch [123/200], Loss: 0.0566\n",
      "Epoch [124/200], Loss: 0.0566\n",
      "Epoch [125/200], Loss: 0.0566\n",
      "Epoch [126/200], Loss: 0.0566\n",
      "Epoch [127/200], Loss: 0.0566\n",
      "Epoch [128/200], Loss: 0.0567\n",
      "Epoch [129/200], Loss: 0.0567\n",
      "Epoch [130/200], Loss: 0.0566\n",
      "Epoch [131/200], Loss: 0.0566\n",
      "Epoch [132/200], Loss: 0.0567\n",
      "Epoch [133/200], Loss: 0.0567\n",
      "Epoch [134/200], Loss: 0.0567\n",
      "Epoch [135/200], Loss: 0.0566\n",
      "Epoch [136/200], Loss: 0.0567\n",
      "Epoch [137/200], Loss: 0.0566\n",
      "Epoch [138/200], Loss: 0.0566\n",
      "Epoch [139/200], Loss: 0.0566\n",
      "Epoch [140/200], Loss: 0.0566\n",
      "Epoch [141/200], Loss: 0.0566\n",
      "Epoch [142/200], Loss: 0.0566\n",
      "Epoch [143/200], Loss: 0.0566\n",
      "Epoch [144/200], Loss: 0.0566\n",
      "Epoch [145/200], Loss: 0.0566\n",
      "Epoch [146/200], Loss: 0.0566\n",
      "Epoch [147/200], Loss: 0.0566\n",
      "Epoch [148/200], Loss: 0.0566\n",
      "Epoch [149/200], Loss: 0.0566\n",
      "Epoch [150/200], Loss: 0.0566\n",
      "Epoch [151/200], Loss: 0.0566\n",
      "Epoch [152/200], Loss: 0.0566\n",
      "Epoch [153/200], Loss: 0.0566\n",
      "Epoch [154/200], Loss: 0.0566\n",
      "Epoch [155/200], Loss: 0.0566\n",
      "Epoch [156/200], Loss: 0.0566\n",
      "Epoch [157/200], Loss: 0.0566\n",
      "Epoch [158/200], Loss: 0.0566\n",
      "Epoch [159/200], Loss: 0.0566\n",
      "Epoch [160/200], Loss: 0.0566\n",
      "Epoch [161/200], Loss: 0.0566\n",
      "Epoch [162/200], Loss: 0.0566\n",
      "Epoch [163/200], Loss: 0.0566\n",
      "Epoch [164/200], Loss: 0.0566\n",
      "Epoch [165/200], Loss: 0.0566\n",
      "Epoch [166/200], Loss: 0.0566\n",
      "Epoch [167/200], Loss: 0.0566\n",
      "Epoch [168/200], Loss: 0.0566\n",
      "Epoch [169/200], Loss: 0.0566\n",
      "Epoch [170/200], Loss: 0.0566\n",
      "Epoch [171/200], Loss: 0.0566\n",
      "Epoch [172/200], Loss: 0.0566\n",
      "Epoch [173/200], Loss: 0.0566\n",
      "Epoch [174/200], Loss: 0.0566\n",
      "Epoch [175/200], Loss: 0.0566\n",
      "Epoch [176/200], Loss: 0.0566\n",
      "Epoch [177/200], Loss: 0.0566\n",
      "Epoch [178/200], Loss: 0.0566\n",
      "Epoch [179/200], Loss: 0.0566\n",
      "Epoch [180/200], Loss: 0.0566\n",
      "Epoch [181/200], Loss: 0.0566\n",
      "Epoch [182/200], Loss: 0.0566\n",
      "Epoch [183/200], Loss: 0.0566\n",
      "Epoch [184/200], Loss: 0.0566\n",
      "Epoch [185/200], Loss: 0.0566\n",
      "Epoch [186/200], Loss: 0.0566\n",
      "Epoch [187/200], Loss: 0.0566\n",
      "Epoch [188/200], Loss: 0.0566\n",
      "Epoch [189/200], Loss: 0.0566\n",
      "Epoch [190/200], Loss: 0.0566\n",
      "Epoch [191/200], Loss: 0.0566\n",
      "Epoch [192/200], Loss: 0.0566\n",
      "Epoch [193/200], Loss: 0.0566\n",
      "Epoch [194/200], Loss: 0.0566\n",
      "Epoch [195/200], Loss: 0.0566\n",
      "Epoch [196/200], Loss: 0.0566\n",
      "Epoch [197/200], Loss: 0.0566\n",
      "Epoch [198/200], Loss: 0.0566\n",
      "Epoch [199/200], Loss: 0.0566\n",
      "Epoch [200/200], Loss: 0.0566\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:01:44.635331Z",
     "start_time": "2024-11-07T12:53:01.181696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongge/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/kongge/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/kongge/.conda/envs/kongge_pytorch_cpu/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_true = y_test_tensor.numpy()\n",
    "\n",
    "    aupr_results = {}\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        aupr = average_precision_score(y_true[:, i], y_pred[:, i])\n",
    "        disease_name = label_columns[i]  # 获取疾病名称\n",
    "        aupr_results[disease_name] = aupr\n",
    "\n",
    "    mean_aupr = np.mean(list(aupr_results.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:13:52.776113Z",
     "start_time": "2024-11-07T13:13:51.113592Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "aupr_results = {k: v for k, v in aupr_results.items() if not np.isnan(v)}\n",
    "sorted_aupr_results = sorted(aupr_results.items(), key=lambda item: item[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:20:51.191445Z",
     "start_time": "2024-11-07T13:20:51.152876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Class_I10', 0.5912832565184755),\n ('Class_J45', 0.31490851466463526),\n ('Class_E03', 0.2942917891416554),\n ('Class_I25', 0.2282831738292497),\n ('Class_F17', 0.21319730023049605),\n ('Class_I48', 0.2029449849522778),\n ('Class_E11', 0.1832767216951004),\n ('Class_I20', 0.1656175298760879),\n ('Class_I21', 0.1163326634024214),\n ('Class_E14', 0.1122783392267296),\n ('Class_D64', 0.09374645342883481),\n ('Class_D50', 0.08475763876397645),\n ('Class_I50', 0.08152256336170131),\n ('Class_A09', 0.0667528275677719),\n ('Class_I63', 0.054549659203597015),\n ('Class_C50', 0.05247698403093434),\n ('Class_F10', 0.04446388752997917),\n ('Class_M05', 0.04403705871575638),\n ('Class_E05', 0.03267414788706921),\n ('Class_I08', 0.029732646551248),\n ('Class_F00', 0.02833188793902882),\n ('Class_F05', 0.027605111426185654),\n ('Class_C18', 0.024829858121088583),\n ('Class_E10', 0.024008670085211785),\n ('Class_F03', 0.023921524685292975),\n ('Class_E16', 0.02082497780809134),\n ('Class_A04', 0.020208493892878855),\n ('Class_D51', 0.01733259068779354),\n ('Class_A08', 0.014841919218366518),\n ('Class_E04', 0.013498356996434488),\n ('Class_I12', 0.011665347704354985),\n ('Class_F01', 0.01071417739566515),\n ('Class_G20', 0.010085981500243518),\n ('Class_E07', 0.00997319567453776),\n ('Class_I22', 0.00812894255156817),\n ('Class_E06', 0.0075942017617480605),\n ('Class_I07', 0.007323492817953895),\n ('Class_F06', 0.006933256365223879),\n ('Class_D63', 0.006380615785648861),\n ('Class_G03', 0.005904212458654534),\n ('Class_A15', 0.0056689247750165905),\n ('Class_D61', 0.004776911829751161),\n ('Class_F12', 0.004660459486877569),\n ('Class_C56', 0.004441408952490162),\n ('Class_F20', 0.004029553289206199),\n ('Class_E13', 0.003748962628212462),\n ('Class_I00', 0.0036821340870908524),\n ('Class_D52', 0.003548177009667521),\n ('Class_F02', 0.0034568899922442203),\n ('Class_I11', 0.003373757592954288),\n ('Class_I05', 0.0031456006780916823),\n ('Class_G04', 0.002117796122940678),\n ('Class_F11', 0.002079422445855353),\n ('Class_A16', 0.0018534528275972288),\n ('Class_A02', 0.0018320624494294231),\n ('Class_G12', 0.001756691044559464),\n ('Class_A07', 0.0013532418685855674),\n ('Class_G06', 0.0012664821252153296),\n ('Class_F09', 0.0012184437063133765),\n ('Class_D53', 0.0011866440220017868),\n ('Class_D62', 0.0011264251805413765),\n ('Class_D59', 0.0010753154344486648),\n ('Class_A05', 0.0010014240896329123),\n ('Class_G11', 0.0009860377043761017),\n ('Class_F07', 0.0007941704534828108),\n ('Class_I13', 0.0007923578561658468),\n ('Class_F13', 0.0007474950803743272),\n ('Class_E02', 0.000694033116392543),\n ('Class_A01', 0.0006928980447101925),\n ('Class_E01', 0.0006925656026121438),\n ('Class_E20', 0.0006480808165632642),\n ('Class_F14', 0.0005848397630348375),\n ('Class_D66', 0.0005620398239410488),\n ('Class_G00', 0.0005255346484233394),\n ('Class_G05', 0.000499128453576485),\n ('Class_A03', 0.0004938003087396541),\n ('Class_G02', 0.0004893269916831976),\n ('Class_F15', 0.0004881317113745524),\n ('Class_D56', 0.0004803592256131915),\n ('Class_D65', 0.0004162549111243936),\n ('Class_D58', 0.00031113773784416886),\n ('Class_A06', 0.00030717209511765787),\n ('Class_G09', 0.00029760391703573957),\n ('Class_G14', 0.0002864345034432509),\n ('Class_I06', 0.00027682585667826687),\n ('Class_G08', 0.00027503894469910016),\n ('Class_G10', 0.00027191159303511153),\n ('Class_D57', 0.00023837565115587215),\n ('Class_I09', 0.00022999653782599137),\n ('Class_A00', 0.00021654395842355997),\n ('Class_G01', 0.00018324023311027545),\n ('Class_E15', 0.00015546098754895212),\n ('Class_A18', 0.00013714267073957118),\n ('Class_I02', 0.0001232442232823481),\n ('Class_G13', 7.113876500112269e-05),\n ('Class_A17', 5.864108889299036e-05),\n ('Class_D60', 4.518488060090643e-05),\n ('Class_F16', 3.809333658735267e-05),\n ('Class_I01', 3.721221965228317e-05),\n ('Class_A19', 3.66921809182177e-05),\n ('Class_D55', 3.35296653493718e-05),\n ('Class_E12', 2.9399658963956018e-05)]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_aupr_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:20:57.165938Z",
     "start_time": "2024-11-07T13:20:57.124054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test, columns=label_columns)\n",
    "test_counts = y_test_df.sum(axis=0)\n",
    "test_counts_dict = test_counts.to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:25:16.455892Z",
     "start_time": "2024-11-07T13:25:16.415244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "sorted_test_counts_dict = sorted(test_counts_dict.items(), key=lambda item: item[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:26:55.834948Z",
     "start_time": "2024-11-07T13:26:55.792395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Class_I10', 27119),\n ('Class_J45', 9971),\n ('Class_I25', 7991),\n ('Class_I48', 6100),\n ('Class_F17', 5897),\n ('Class_E11', 5825),\n ('Class_E03', 5442),\n ('Class_I20', 5112),\n ('Class_D64', 4756),\n ('Class_D50', 4236),\n ('Class_A09', 3608),\n ('Class_I21', 3424),\n ('Class_E14', 3273),\n ('Class_I50', 2923),\n ('Class_C50', 2585),\n ('Class_I63', 2417),\n ('Class_F10', 1859),\n ('Class_M05', 1774),\n ('Class_C18', 1436),\n ('Class_I08', 1260),\n ('Class_F05', 1228),\n ('Class_E05', 1160),\n ('Class_A04', 1113),\n ('Class_A08', 775),\n ('Class_E04', 729),\n ('Class_F03', 719),\n ('Class_E16', 666),\n ('Class_E10', 652),\n ('Class_F00', 623),\n ('Class_G20', 618),\n ('Class_D51', 512),\n ('Class_E07', 416),\n ('Class_G03', 357),\n ('Class_A15', 320),\n ('Class_F01', 314),\n ('Class_I07', 307),\n ('Class_I12', 265),\n ('Class_C56', 264),\n ('Class_D63', 263),\n ('Class_D61', 240),\n ('Class_F06', 229),\n ('Class_I00', 220),\n ('Class_E06', 207),\n ('Class_D52', 158),\n ('Class_F20', 157),\n ('Class_F02', 148),\n ('Class_I05', 131),\n ('Class_I22', 128),\n ('Class_I11', 125),\n ('Class_G04', 122),\n ('Class_G12', 116),\n ('Class_A02', 102),\n ('Class_E13', 90),\n ('Class_A07', 74),\n ('Class_F09', 73),\n ('Class_A16', 72),\n ('Class_G11', 67),\n ('Class_A05', 63),\n ('Class_D62', 60),\n ('Class_D59', 58),\n ('Class_F12', 58),\n ('Class_G06', 51),\n ('Class_F11', 40),\n ('Class_D53', 38),\n ('Class_F07', 35),\n ('Class_F13', 35),\n ('Class_G00', 33),\n ('Class_G05', 30),\n ('Class_A03', 29),\n ('Class_D56', 29),\n ('Class_E20', 28),\n ('Class_E02', 23),\n ('Class_G02', 22),\n ('Class_I13', 22),\n ('Class_D58', 21),\n ('Class_D65', 17),\n ('Class_D66', 17),\n ('Class_G09', 17),\n ('Class_G14', 17),\n ('Class_A01', 16),\n ('Class_G08', 16),\n ('Class_E01', 14),\n ('Class_F15', 14),\n ('Class_I06', 13),\n ('Class_A18', 12),\n ('Class_G10', 12),\n ('Class_I09', 12),\n ('Class_F14', 10),\n ('Class_G01', 8),\n ('Class_A06', 7),\n ('Class_D57', 7),\n ('Class_E15', 6),\n ('Class_I02', 5),\n ('Class_G13', 4),\n ('Class_A17', 3),\n ('Class_D60', 3),\n ('Class_F16', 3),\n ('Class_I01', 3),\n ('Class_A19', 2),\n ('Class_D55', 2),\n ('Class_A00', 1),\n ('Class_E12', 1),\n ('Class_E00', 0),\n ('Class_F04', 0),\n ('Class_G07', 0)]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_test_counts_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T13:27:09.048680Z",
     "start_time": "2024-11-07T13:27:09.028523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 患病人数越多的类，aupr的指数越高。"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
